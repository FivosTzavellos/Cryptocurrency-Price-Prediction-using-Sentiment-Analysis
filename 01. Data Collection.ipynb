{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations - points of inspiration for the whole project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work of Mohapatra, Ahmed and Alencar has been of great inspiration to me (https://github.com/Nomiizz/KryptoOracle) during my time of writing code down, as well as countless stackoverflow posts to troubleshoot and surpass certain obstacles and TowardsDataScience pages to fetch for ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T08:43:28.500897Z",
     "start_time": "2021-08-10T08:43:27.937300Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "from twython import Twython\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:03:56.366774Z",
     "start_time": "2021-04-21T07:03:56.355271Z"
    }
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path\n",
    "tweets_notclean = 'Data Collection/twitter/BTC/bitcoin_tweets_notclean.csv' # The file where we will store the tweets before preprocessing them\n",
    "query = '#bitcoin OR #BTC OR bitcoin OR BTC OR $BTC' # Our query to use when searching for tweets\n",
    "tweets_notclean_nextid = 'Data Collection/twitter/BTC/bitcoin_tweets_notclean_week_nextid.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:03:58.398858Z",
     "start_time": "2021-04-21T07:03:57.615064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/search/tweets': {'limit': 450, 'remaining': 450, 'reset': 1618989538}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_KEY ='gU1T2G85YKFZVNr0i9Mx6rTh1'  # We got these from our app on the Twitter Developer Dashboard\n",
    "API_SECRET_KEY =  'Kl1TT1C0zY7NPnD1TF6XPS0nfZfY3dT1XZlb1CDBlzFIu9Qqhh' \n",
    "twitter = Twython(API_KEY, API_SECRET_KEY, oauth_version=2) # We use version 2 because it allows us to get more tweets\n",
    "ACCESS_TOKEN = twitter.obtain_access_token()\n",
    "twitter = Twython(API_KEY, access_token=ACCESS_TOKEN)\n",
    "twitter.get_application_rate_limit_status()['resources']['search'] # We check to see what the rate limit is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Extraction Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Twitter Developer account that we obtained after applying for it to make a stream that extracts tweets that contain one (or more) of the terms 'bitcoin' , '#BTC' , '#bitcoin', 'BTC', '$BTC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:45:58.918638Z",
     "start_time": "2021-04-21T07:04:00.498006Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450/450 [01:49<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 0, waiting for 15 minutes until next queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450/450 [01:51<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 0, waiting for 15 minutes until next queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450/450 [01:46<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 0, waiting for 15 minutes until next queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450/450 [01:49<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 0, waiting for 15 minutes until next queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450/450 [01:51<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 0, waiting for 15 minutes until next queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450/450 [01:49<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 0, waiting for 15 minutes until next queries\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e3bd58e8c106>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"statuses\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m910\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#we sleep for 15 minutes so that the rate limit gets renewed after we exceed it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterations = 450\n",
    "data = {\"statuses\": []} # Dictionary to store the data values\n",
    "next_id = \"\" # This will indicate the id of the next tweet\n",
    "since_id= \"\" # This will indicate the flag, ids that are greater than the flag (more recent) will be returned\n",
    "\n",
    "with open(tweets_notclean_nextid,\"a+\", encoding='utf-8') as f: \n",
    "    # a+ : Open for reading and writing. The file is created if it does not exist. \n",
    "    # The stream is positioned at the end of the file.\n",
    "    \n",
    "    if not next_id and not since_id: #if there is no next_id and no since_id:\n",
    "        f.write(\"ID,Text,UserName,UserFollowerCount,RetweetCount,Likes,CreatedAt\\n\") \n",
    "        # The first row of our csv will be the column names\n",
    "        \n",
    "    while(True):\n",
    "        twitter = Twython(API_KEY, access_token=ACCESS_TOKEN)\n",
    "        size = 0 # Indicates the size so that we know when we stop\n",
    "        \n",
    "        for i in tqdm(range(iterations)): # Repeat for 450 times (our rate limit)\n",
    "            \n",
    "            if not next_id:\n",
    "                data = twitter.search(q=query, lang='en', result_type='recent', count=\"100\",tweet_mode='extended',since_id=since_id) \n",
    "                # At the start (next_id is blank) we search for the most recent tweets (100 of them per iteration) and set the since_id to blank for the first iteration\n",
    "            elif since_id:\n",
    "                data[\"statuses\"].extend(twitter.search(q=query, lang='en', result_type='mixed', count=\"100\",max_id=next_id,tweet_mode='extended')[\"statuses\"])\n",
    "                # We set the max_id to be the id of  the last status, so that we can collect tweets with ids older than the max_id\n",
    "            else: # If next_id exists and there is no since_id\n",
    "                data[\"statuses\"].extend(twitter.search(q=query, lang='en', result_type='mixed', count=\"100\", max_id=next_id,tweet_mode='extended')[\"statuses\"])\n",
    "                # We set the max_id to be the id of  the last status, so that we can collect tweets with ids older than the max_id\n",
    "                \n",
    "            if len(data[\"statuses\"]) > 1: # If we have more than one statuses collected we set next_id to be the id of the last status\n",
    "                next_id = data[\"statuses\"][len(data[\"statuses\"]) - 1]['id']\n",
    "            if size + 1 == len(data[\"statuses\"]): # If we can't collect any more statuses (we reached our limit for this iteration ie 100 tweets)\n",
    "                break\n",
    "            else:\n",
    "                size = len(data[\"statuses\"])\n",
    "            \n",
    "        print('Retrieved {0}, waiting for 15 minutes until next queries'.format(len(data[\"statuses\"])))\n",
    "        \n",
    "        d = pd.DataFrame([[s[\"id\"], s[\"full_text\"].replace('\\n','').replace('\\r',''), s[\"user\"][\"name\"], s[\"user\"][\"followers_count\"], s[\"retweet_count\"], s[\"favorite_count\"], s[\"created_at\"]] for s in data[\"statuses\"]], columns=('ID', 'Text', 'UserName', \"UserFollowerCount\", 'RetweetCount', 'Likes', \"CreatedAt\"))\n",
    "        # We make a pandas dataframe to store our tweets, where we replace the newline characters and the tab characters with a space on the texts\n",
    "        d.to_csv(f, mode='a', encoding='utf-8',index=False,header=False)\n",
    "        if size + 1 == len(data[\"statuses\"]):\n",
    "            print('No more new tweets, stopping...')\n",
    "            break \n",
    "        data[\"statuses\"] = []\n",
    "        \n",
    "        sleep(910) # We sleep for 15 minutes so that the rate limit gets renewed after we exceed it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#week 1\n",
    "# 1.543.263 tweets collected, 11h 2min 13sec\n",
    "# start date Sat Mar 13 11:47:11 +0000 2021, end date Sat Mar 06 03:47:49 +0000 2021\n",
    "# 7 days + 8 hours back\n",
    "\n",
    "#week 2\n",
    "# 1.875.727 tweets collected\n",
    "# start date Sun Mar 28 8:26, end date Sat Mar 20 18h:17\n",
    "# 7 days + 14 hours\n",
    "\n",
    "\n",
    "#week 3 \n",
    "# 1.546.735 tweets collected, 11h 12min 38sec\n",
    "# start date Sat Apr 03 09:01:12 +0000 2021, end date Fri Mar 26 15:00:03 +0000 2021\n",
    "# pige 7 meres + 18 wres pisw\n",
    "\n",
    "#week4 \n",
    "# 1.550.457 tweets collected, 11h 9min 38sec\n",
    "# start date Sat Apr 10 09:01:00 +0000 2021, end date Sat Apr 03 01:00:43 +0000 2021\n",
    "# pige 7 meres + 8 wres pisw\n",
    "\n",
    "#there is a 1.5 days gap between week 4 and week 5\n",
    "#week5 \n",
    "# 2.093.415  tweets collected\n",
    "#start date Mon Apr 19 21:39:51 +0000 2021, end date Sun Apr 11 19:49:24 +0000 2021\n",
    "\n",
    "\n",
    "#total 7.066.334\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a function that rounds time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to make code that converts all the elements of the CreatedAt column from str to datetime and then rounds \n",
    " each element to the hour or to the 15 minute mark (depends on the time window we decide to get). We also use this function in the Prediction Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T08:59:25.260882Z",
     "start_time": "2021-08-10T08:59:23.454565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>UserName</th>\n",
       "      <th>UserFollowerCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>Likes</th>\n",
       "      <th>CreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1384521088089079808</td>\n",
       "      <td>$CELOLatest add into my portfolio is #celo.We ...</td>\n",
       "      <td>Siho</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue Apr 20 14:55:25 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1384521088038752257</td>\n",
       "      <td>*3IQ DIGITAL ASSET MGMT TO LIST BITCOIN FUND O...</td>\n",
       "      <td>sellvolbuytesla</td>\n",
       "      <td>603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue Apr 20 14:55:25 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1384521087912927234</td>\n",
       "      <td>Bitcoin keeps getting rejected from many trend...</td>\n",
       "      <td>Crypto Bible</td>\n",
       "      <td>36798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue Apr 20 14:55:25 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1384521087057203201</td>\n",
       "      <td>RT @michael_saylor: #Bitcoin on Venmo for 70 m...</td>\n",
       "      <td>cjglory</td>\n",
       "      <td>525</td>\n",
       "      <td>1141</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue Apr 20 14:55:24 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1384521086369476609</td>\n",
       "      <td>Tue Apr 20 16:54:13 2021 (30:40)USD : 55,462.7...</td>\n",
       "      <td>Block Watcher</td>\n",
       "      <td>909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue Apr 20 14:55:24 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539205</th>\n",
       "      <td>1383792115134599179</td>\n",
       "      <td>RT @MocktailSwap: Say Hello to our MocktailSwa...</td>\n",
       "      <td>Justice</td>\n",
       "      <td>39</td>\n",
       "      <td>4038</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Apr 18 14:38:44 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539206</th>\n",
       "      <td>1383792114832613376</td>\n",
       "      <td>RT @justinsuntron: #TRX now is the most active...</td>\n",
       "      <td>Ojo Ibukunoluwa</td>\n",
       "      <td>31</td>\n",
       "      <td>2195</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Apr 18 14:38:44 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539207</th>\n",
       "      <td>1383792114153050126</td>\n",
       "      <td>RT @michael_saylor: In preparation for my upco...</td>\n",
       "      <td>On The Hunt #BuyBitcoin</td>\n",
       "      <td>265</td>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Apr 18 14:38:44 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539208</th>\n",
       "      <td>1383792113347743749</td>\n",
       "      <td>RT @Udedibia: FOX to the moonðŸš€ #FOXFINANCE #FO...</td>\n",
       "      <td>RushikeshðŸ–¤</td>\n",
       "      <td>2377</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Apr 18 14:38:44 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539209</th>\n",
       "      <td>1383792112290852864</td>\n",
       "      <td>RT @michael_saylor: In preparation for my upco...</td>\n",
       "      <td>VeeCal #7.21</td>\n",
       "      <td>10</td>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Apr 18 14:38:43 +0000 2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539210 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID  \\\n",
       "0       1384521088089079808   \n",
       "1       1384521088038752257   \n",
       "2       1384521087912927234   \n",
       "3       1384521087057203201   \n",
       "4       1384521086369476609   \n",
       "...                     ...   \n",
       "539205  1383792115134599179   \n",
       "539206  1383792114832613376   \n",
       "539207  1383792114153050126   \n",
       "539208  1383792113347743749   \n",
       "539209  1383792112290852864   \n",
       "\n",
       "                                                     Text  \\\n",
       "0       $CELOLatest add into my portfolio is #celo.We ...   \n",
       "1       *3IQ DIGITAL ASSET MGMT TO LIST BITCOIN FUND O...   \n",
       "2       Bitcoin keeps getting rejected from many trend...   \n",
       "3       RT @michael_saylor: #Bitcoin on Venmo for 70 m...   \n",
       "4       Tue Apr 20 16:54:13 2021 (30:40)USD : 55,462.7...   \n",
       "...                                                   ...   \n",
       "539205  RT @MocktailSwap: Say Hello to our MocktailSwa...   \n",
       "539206  RT @justinsuntron: #TRX now is the most active...   \n",
       "539207  RT @michael_saylor: In preparation for my upco...   \n",
       "539208  RT @Udedibia: FOX to the moonðŸš€ #FOXFINANCE #FO...   \n",
       "539209  RT @michael_saylor: In preparation for my upco...   \n",
       "\n",
       "                       UserName  UserFollowerCount  RetweetCount  Likes  \\\n",
       "0                          Siho                146             0      0   \n",
       "1               sellvolbuytesla                603             0      0   \n",
       "2                  Crypto Bible              36798             0      0   \n",
       "3                       cjglory                525          1141      0   \n",
       "4                 Block Watcher                909             0      0   \n",
       "...                         ...                ...           ...    ...   \n",
       "539205                  Justice                 39          4038      0   \n",
       "539206          Ojo Ibukunoluwa                 31          2195      0   \n",
       "539207  On The Hunt #BuyBitcoin                265           899      0   \n",
       "539208               RushikeshðŸ–¤               2377            33      0   \n",
       "539209             VeeCal #7.21                 10           899      0   \n",
       "\n",
       "                             CreatedAt  \n",
       "0       Tue Apr 20 14:55:25 +0000 2021  \n",
       "1       Tue Apr 20 14:55:25 +0000 2021  \n",
       "2       Tue Apr 20 14:55:25 +0000 2021  \n",
       "3       Tue Apr 20 14:55:24 +0000 2021  \n",
       "4       Tue Apr 20 14:55:24 +0000 2021  \n",
       "...                                ...  \n",
       "539205  Sun Apr 18 14:38:44 +0000 2021  \n",
       "539206  Sun Apr 18 14:38:44 +0000 2021  \n",
       "539207  Sun Apr 18 14:38:44 +0000 2021  \n",
       "539208  Sun Apr 18 14:38:44 +0000 2021  \n",
       "539209  Sun Apr 18 14:38:43 +0000 2021  \n",
       "\n",
       "[539210 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets1 = pd.read_csv(r\"C:\\Users\\Fivos\\Desktop\\Î Ï„Ï…Ï‡Î¹Î±ÎºÎ®\\Data Collection\\twitter\\BTC\\bitcoin_tweets_notclean_Tue20-4_14h55m_Sun18-4_14h38m.csv\")\n",
    "tweets1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T08:59:38.296745Z",
     "start_time": "2021-08-10T08:59:38.293245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tue Apr 20 14:55:25 +0000 2021'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = tweets1['CreatedAt'][0]\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T08:59:53.020806Z",
     "start_time": "2021-08-10T08:59:53.002803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-20 14:55:25\n"
     ]
    }
   ],
   "source": [
    "new_t1 = datetime.strptime(t1,'%a %b %d %H:%M:%S +0000 %Y')\n",
    "print(new_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T08:59:54.245521Z",
     "start_time": "2021-08-10T08:59:54.236019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T08:59:57.346065Z",
     "start_time": "2021-08-10T08:59:57.329062Z"
    }
   },
   "outputs": [],
   "source": [
    "def roundTime(dt=None, roundTo=60):\n",
    "   \"\"\"Round a datetime object to any time lapse in seconds\n",
    "   dt : datetime.datetime object, default now.\n",
    "   roundTo : Closest number of seconds to round to, default 1 minute.\n",
    "   Author: Thierry Husson 2012 - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "   if dt == None : dt = datetime.datetime.now()\n",
    "   seconds = (dt.replace(tzinfo=None) - dt.min).seconds\n",
    "   rounding = (seconds+roundTo/2) // roundTo * roundTo\n",
    "   return dt + timedelta(0,rounding-seconds,-dt.microsecond)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T08:59:59.795496Z",
     "start_time": "2021-08-10T08:59:59.782495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-20 15:00:00\n"
     ]
    }
   ],
   "source": [
    "roundedt1 = roundTime(new_t1,60*15)\n",
    "#we round it to 15 minutes in this example\n",
    "print(roundedt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T22:04:47.096174Z",
     "start_time": "2021-03-19T17:16:39.429103Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets1['FlooredDatatime'] = 0\n",
    "for i in tqdm(range(len(tweets1))):\n",
    "    tweets1['FlooredDatatime'][i] = roundTime(datetime.strptime(tweets1['CreatedAt'][i],'%a %b %d %H:%M:%S +0000 %Y'),60*15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
